This report details my approach for multinational logistic regression.
My reading material can be found here:  http://www.statisticssolutions.com/mlr/

I will be looking at student performance at different levels. For the middle east data set, score is already segmented into three levels: low, medium, and high.

I will convert the Portugal data into three levels. The student score is nominal, but I will apply a low, medium, and high metric to the score.

I will run several experiments:
I will run both math and Portugal language datasets with f-test-selected features and evaluate performance
I will run both math and Portugal language datasets without f-test selected features
I will run both math and Portugal language datasets with L2 regularization.
I will run the middle east dataset with and without L2 regularization.
   

Results on the middle east dataset:
The model uses a random 2/3 splits for training and test data.
I ran the model 20 times and took an average of the model’s accuracy for different L2 penalty values. I did this by manually changing the script. My model peaked out around 76% accuracy. Here are the results of my experiments:

0.001: approx 63%
0.01: approx 66%
0.05: approx 70%
0.1: approx 74%
0.5: approx 76%

Results on the potugal datasets:
I’m first going to start with no feature selection and use L2 regularization.

Results on the Portuguese math scores.
0.001: approx 57%
0.01: approx 60%
0.05: approx 60%
0.1: approx 60%
0.5: approx 57%


Next, I use the f-tested features at 10% significance level:
Results on the Portuguese math scores.
0.001: approx 57%
0.01 approx 57%
0.1: approx 57%
0.5: approx 55%

Next, I use the f-tested features at 5% significance levels:
Results on the Portuguese math scores.
0.001: approx 58%
0.01: approx 58%
0.05: approx 58%
0.1: approx 56%
0.5: approx 56%


Results on Portuguese langauge scores:
I’m first going to start with no feature selection and use L2 regularization.
Results on Portuguese language scores.
0.001: approx 62%
0.01: approx 66%
0.05: approx 66%
0.1: approx 65%
0.5: approx 65%

Next, I use the f-tested features at 10% significance level: (note, few features were removed)
Results on Portuguese language scores.
0.001: approx 61%
0.01: 66%
0.05: 66%
0.1: 66%
0.5: 66%

Next, I use the f-tested features at 5% significance level:
Results on Portuguese language scores.
0.001: 62%
0.01: 66%
0.05: 66%
0.1: 66%
0.5: 65%


Concluding comments:
Overall, it appears that our feature selection technique did not hurt the performance of the logistic regression, with the possible exception of the Portuguese math scores. However, this experiment did demonstrate that many of that features may be removed from the various Portugal data sets without hurting performance, which speaks to those features’ relevance. 

I also performed these tests with boosting using scikit learn’s built in implementation of Adaboost. However, performance worsened, which leads me too assume that the data was noisy and was hurt by boosting.














